# N8N Workflow Scraper - Production Architecture
# Version: 3.0 - With Redis for Global Connection Coordination
# Purpose: Clean separation with working Supabase connection + Redis coordination

services:
  # ============================================================================
  # REDIS - Connection Coordinator (Scraper Project Only)
  # ============================================================================
  scraper-redis:
    image: redis:7-alpine
    container_name: n8n-scraper-redis
    restart: unless-stopped
    
    command: redis-server --appendonly yes --maxmemory 256mb --maxmemory-policy allkeys-lru
    
    volumes:
      - scraper-redis-data:/data
    
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 3
    
    networks:
      - n8n-scraper-network
    
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.25'

  # ============================================================================
  # APPLICATION SERVICE - Connects directly to Supabase
  # ============================================================================
  n8n-scraper-app:
    build: 
      context: ..
      dockerfile: n8n-scraper/Dockerfile
    container_name: n8n-scraper-app
    restart: unless-stopped
    
    depends_on:
      scraper-redis:
        condition: service_healthy
    
    # Environment variables
    environment:
      # Database connection (DIRECT TO SUPABASE)
      DATABASE_URL: postgresql://postgres.skduopoakfeaurttcaip:crg3pjm8ych4ctu%40KXT@aws-1-eu-north-1.pooler.supabase.com:5432/postgres
      
      # Redis connection coordination (SCRAPER PROJECT ONLY)
      REDIS_URL: redis://scraper-redis:6379
      SERVICE_NAME: scraper
      SUPABASE_PLAN: free
      SUPABASE_MAX_CONNECTIONS: 60
      
      # Application settings
      PYTHONPATH: /app
      PYTHONUNBUFFERED: 1
      SCRAPER_ENV: production
      SCRAPER_LOG_LEVEL: INFO
      
      # Browser settings
      BROWSER_HEADLESS: "true"
      BROWSER_TIMEOUT: 30000
      BROWSER_VIEWPORT_WIDTH: 1920
      BROWSER_VIEWPORT_HEIGHT: 1080
      
      # Rate limiting
      RATE_LIMIT_REQUESTS_PER_MINUTE: 60
      RATE_LIMIT_BURST_SIZE: 10
      
      # Retry settings
      MAX_RETRIES: 3
      RETRY_DELAY: 2
      
      # Batch processing
      BATCH_SIZE: 10
      MAX_CONCURRENT_WORKFLOWS: 5
      
      # Monitoring
      ENABLE_METRICS: "true"
      METRICS_PORT: 9090
      
      # Security
      ENABLE_SSL: "true"
      SSL_VERIFY: "true"
    
    # Port mappings
    ports:
      - "5001:5001"  # WebSocket Dashboard (HTTP)
      - "5002:5002"  # WebSocket Dashboard (WebSocket)
      # Database Viewer now runs separately on port 8080 (n8n-workflow-viewer)
    
    # Volume mounts
    volumes:
      - ./logs:/app/logs
      - ./data:/app/data
      - ./scripts:/app/scripts
      - ./src:/app/src
      - ./tests:/app/tests
      - ./evidence:/app/evidence
    
    # Network configuration
    networks:
      - n8n-scraper-network
    
    # Health check
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5001/api/stats"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    
    # No local database dependency - connects directly to Supabase
    
    # Resource limits
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.0'
        reservations:
          memory: 1G
          cpus: '0.5'

# ============================================================================
# VOLUMES
# ============================================================================
volumes:
  scraper-redis-data:
    driver: local

# ============================================================================
# NETWORKS
# ============================================================================
networks:
  n8n-scraper-network:
    name: n8n-scraper-network
    driver: bridge
